# -*- coding: utf-8 -*-
"""Parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z9L5N0VblOyqUWR3dI8dvJy_OooSwr9e
"""

pip install PyMuPDF

pip install frontend

pip install fitz

import io
import os
import datetime
from pdfminer.converter import HTMLConverter
from pdfminer.layout import LAParams
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.pdfpage import PDFPage
from bs4 import BeautifulSoup
import pandas as pd
import re

# Convert PDF to HTML
def pdftohtml(pdf_file):
    output_file_path = f"processed_{current_time()}.html"
    rsrcmgr = PDFResourceManager()
    laparams = LAParams()

    with io.BytesIO() as output_stream, open(pdf_file, 'rb') as input_file:
        converter = HTMLConverter(rsrcmgr, output_stream, laparams=laparams)
        interpreter = PDFPageInterpreter(rsrcmgr, converter)

        for _ in PDFPage.get_pages(input_file):
            interpreter.process_page(_)

        converter.close()
        html_content = output_stream.getvalue().decode()

    with open(output_file_path, 'w') as output_file:
        output_file.write(html_content)

    return output_file_path

def get_pdf_file():
    input_file_path = '/content/the_new_economics_of_ip_081423.pdf'  # Path to the PDF file uploaded by the user
    if os.path.isfile(input_file_path):
        return input_file_path
    else:
        raise FileNotFoundError("PDF file not found.")
def current_time():
    return datetime.datetime.now().strftime("%d-%m-%Y_%H-%M-%S")

# Convert HTML to CSV
def html_to_csv(html_file_name):
    with open(html_file_name) as f:
        soup = BeautifulSoup(f, 'html.parser')

    headings = []


    divs = soup.find_all('div')

    for div in divs:
        style = div.get('style', '').lower()

        top_value = re.search(r'top:(\d+)px', style)
        if top_value:
            top_value = int(top_value.group(1))
        else:
            top_value = None


        left_value = re.search(r'left:(\d+)px', style)
        if left_value:
            left_value = int(left_value.group(1))
        else:
            left_value = None

        for span in div.find_all('span'):
            style = span.get('style', '').lower()


            font_size_match = re.search(r'font-size:(\d+)px', style)
            if font_size_match:
                font_size = int(font_size_match.group(1))
            else:
                font_size = None

            content = span.get_text().strip()

            # Detect headings and subheadings
            if 'bold' in style or '<b>' in span.decode_contents() or '<strong>' in span.decode_contents():
                # Determine type based on font size and left alignment
                if font_size and font_size >= 14 and left_value and left_value < 100:
                    tag_type = 'heading'
                elif font_size and font_size >= 12 and left_value and left_value >= 100:
                    tag_type = 'subheading'
                else:
                    tag_type = 'subheading' if left_value and left_value > 100 else 'heading'

                headings.append({'data': content, 'type': tag_type})


    if not headings:
        raise ValueError("No headings found. Please check the PDF content or parsing logic.")


    df = pd.DataFrame(headings)
    df['Categ'] = df['data'].where(df['type'] == 'heading').ffill()
    df['Sub_cat'] = df['data'].where(df['type'] == 'subheading').ffill()


    csv_file_name = f"headings_subheadings_{current_time()}.csv"
    df.to_csv(csv_file_name, index=False)
    print(f"CSV file created: {csv_file_name}")

def parser():
    pdf_file_path = get_pdf_file()
    print(f"PDF file path: {pdf_file_path}")

    processed_html = pdftohtml(pdf_file_path)
    html_to_csv(processed_html)

parser()

!sudo apt-get install tesseract-ocr

!apt-get install poppler-utils
!pip install pdf2image

!pip install PyPDF2

!pip install pdf2image

!pip install pytesseract

!pip install pdfminer.six